# greek-GEEK
Υλοποίηση του συστήματος αναγνώρισης και αποσαφήνισης ονοματικών οντοτήτων GEEK για τα Ελληνικά.

Ο κώδικας υλοποιεί το σύστημα αναγνώρισης και αποσαφήνισης ονοματικών οντοτήτων σε κείμενο, όπως αναλύεται στη δημοσίευση ["Alexios Mandalios, Konstantinos Tzamaloukas, Alexandros Chortaras, and Giorgos Stamou. Geek: Incremental graph-based entity disambiguation. 2018."](http://events.linkeddata.org/ldow2018/papers/LDOW2018_paper_8.pdf)

Οι αλλαγές σε σχέση με το αρχικό σύστημα GEEK, που λειτουργεί στα Αγγλικά, είναι οι εξής:

* Η αναγνώριση ονοματικών οντοτήτων γίνεται με χρήση της υπηρεσίας του Ινστιτούτου Επεξεργασίας του Λόγου (ΙΕΛ): http://nlp.ilsp.gr/soaplab2-axis/.

* Αντί για τη χρήση του Google Knowledge Graph για την παραγωγή των υποψήφιων οντοτήτων, χρησιμοποιείται η γραφηματική βάση δεδομένων Neo4j.

Ο πυρήνας της μεθόδου, που είναι η αναπαράσταση του κειμένου σε μορφή γράφου, ο οποίος σταδιακά περιορίζεται με άπληστο τρόπο, μέχρι να καταλήξουμε σε μία μόνο υποψήφια οντότητα ανά αναφορά, διατηρείται ως έχει. 

Για να λειτουργήσει το σύστημα, απαιτείται η κατασκευή του γράφου της Wikipedia σε μια εγκατάσταση του Neo4j. Οι κόμβοι αυτής της γραφηματικής βάσης δεδομένων αναπαριστούν σελίδες της Wikipedia, ενώ οι ακμές LINKS και REDIRECTS έχουν το αντίστοιχο νόημα.

Ένα παράδειγμα που παρουσιάζει ένα redirect και έναν εισερχόμενο σύνδεσμο για τη σελίδα του πρώην Αμερικανού προέδρου Μπαράκ Ομπάμα ακολουθεί, ώστε να γίνει κατανοητή η δομή της βάσης δεδομένων:

<p align="center"><img src="https://github.com/Alekos92/greek-GEEK/blob/master/graph.svg"/></p>


Για την εκτέλεση του κώδικα, εκτελούνται οι εξής εντολές:

`export PYTHONIOENCODING=UTF-8`

`python flask_api.py`

Η εφαρμογή ακούει στην πόρτα 20000, και μπορεί να κληθεί με δύο τρόπους. 

## Ανάλυση ελεύθερου κειμένου

Η ανάλυση ελεύθερου κειμένου μπορεί να γίνει με το εξής GET request:
`http://0.0.0.0:20000/?text=<text>`

Για παράδειγμα, το request:

`http://0.0.0.0:20000/?text=Ο Ομπάμα είναι πρώην πρωθυπουργός των ΗΠΑ.`

δίνει σαν αποτέλεσμα το json:

`[{"end_offset":41,"matched_string":"ΗΠΑ","start_offset":38,"wiki_page":"https://el.wikipedia.org/wiki/ΗΠΑ"}]`

## Ανάλυση λίστας όρων

Όπως φάνηκε παραπάνω, είναι πιθανό να μην αναγνωρίζονται όροι που θα θέλαμε να αναγνωριστούν, με αποτέλεσμα να έχουμε χαμηλή ανάκληση (recall). Αυτό μπορεί να διορθωθεί χρησιμοποιώντας τη δυνατότητα ανάλυσης μιας λίστας όρων, χωρισμένων από κάποιο διαχωριστικό:

`http://0.0.0.0:20000/?list=<term>[<sep><term>]*&separator=<sep>`

Για παράδειγμα, το request που περιέχει όρους από το ίδιο κείμενο είναι:

`http://0.0.0.0:20000/?list=Ομπάμα,πρωθυπουργός,ΗΠΑ&separator=,`

Το αποτέλεσμα είναι το json:

`[{"Ομπάμα":"https://el.wikipedia.org/wiki/Μπαράκ_Ομπάμα"},{"πρωθυπουργός":"https://el.wikipedia.org/wiki/Πρωθυπουργός"},{"ΗΠΑ":"https://el.wikipedia.org/wiki/ΗΠΑ"}]`

Παρατηρούμε ότι το σύστημα αντιστοιχίζει με την Wikipedia και τους άλλους όρους που δεν βρέθηκαν αυτόματα στο κείμενο.



